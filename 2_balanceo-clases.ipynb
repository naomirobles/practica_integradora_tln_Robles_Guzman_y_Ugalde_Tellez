{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "305933b3",
   "metadata": {},
   "source": [
    "# Balanceo de Clases para Clasificación de Noticias\n",
    "\n",
    "Este notebook implementa técnicas de balanceo de datos para un dataset de noticias:\n",
    "- **Undersampling**: Para clases con muchas muestras (Macroeconomía, Alianzas)\n",
    "- **Oversampling**: Para clases con pocas muestras (Regulaciones, Sostenibilidad, Otra, Reputación)\n",
    "\n",
    "Al final se obtendra un dataset balanceado con 200 muestras por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3219d6c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "from gensim.models.doc2vec import Word2Vec, Doc2Vec, TaggedDocument\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Configurar semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bee21",
   "metadata": {},
   "source": [
    "----\n",
    "## 1. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e89f40d6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargar_datos_originales() -> Tuple[List[List[str]], List[str]]:\n",
    "    # Cargar documentos tokenizados\n",
    "    with open('archivos/lemas_por_documento.txt', 'r', encoding='utf-8') as f:\n",
    "        docs = [eval(line.strip()) for line in f]\n",
    "    \n",
    "    # Cargar etiquetas desde el CSV\n",
    "    df = pd.read_csv('recursos/news.csv')\n",
    "    etiquetas = df['Type'].tolist()\n",
    "    \n",
    "    print(f\"Total de documentos cargados: {len(docs)}\")\n",
    "    print(f\"Total de etiquetas cargadas: {len(etiquetas)}\")\n",
    "    \n",
    "    # Verificar que coincidan\n",
    "    assert len(docs) == len(etiquetas), \"El número de documentos y etiquetas no coincide\"\n",
    "    \n",
    "    return docs, etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c90e29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mostrar_distribucion_clases(etiquetas: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Muestra la distribución actual de clases.\n",
    "    \"\"\"\n",
    "    df_temp = pd.DataFrame({'Type': etiquetas})\n",
    "    distribucion = df_temp['Type'].value_counts()\n",
    "    \n",
    "    print(\"Distribución actual de clases:\")\n",
    "    print(distribucion)\n",
    "    print(f\"\\nTotal de documentos: {len(etiquetas)}\")\n",
    "    \n",
    "    return distribucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd01d7e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos cargados: 1217\n",
      "Total de etiquetas cargadas: 1217\n",
      "Distribución actual de clases:\n",
      "Type\n",
      "Macroeconomia     340\n",
      "Alianzas          247\n",
      "Innovacion        195\n",
      "Regulaciones      142\n",
      "Sostenibilidad    137\n",
      "Otra              130\n",
      "Reputacion         26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total de documentos: 1217\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos originales\n",
    "documentos_originales, etiquetas_originales = cargar_datos_originales()\n",
    "distribucion_original = mostrar_distribucion_clases(etiquetas_originales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a6634",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Entrenamiento del Modelo Doc2Vec\n",
    "\n",
    "Entrenamos un modelo Doc2Vec con todos los documentos originales para crear vectorizaciones consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c15925f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def entrenar_doc2vec_global(documentos: List[List[str]], vector_size: int = 100) -> Doc2Vec:\n",
    "    # Preparar documentos etiquetados\n",
    "    tagged_data = [TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(documentos)]\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model = Doc2Vec(\n",
    "        tagged_data, \n",
    "        vector_size=vector_size, \n",
    "        window=10, \n",
    "        min_count=1, \n",
    "        dm=0, \n",
    "        epochs=20, \n",
    "        workers=4\n",
    "    )\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model.save(\"archivos/doc2vec_model_global\")\n",
    "    print(f\"Modelo guardado. Dimensión de vectores: {vector_size}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74999c6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado. Dimensión de vectores: 100\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo global\n",
    "modelo_doc2vec = entrenar_doc2vec_global(documentos_originales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b8045",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Funciones de Balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8b352",
   "metadata": {},
   "source": [
    "### 3.1 Undersampling con Near Miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b19ffa39",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def aplicar_undersampling(documentos: List[List[str]], etiquetas: List[str], \n",
    "                         clases_objetivo: List[str], n_muestras: int,\n",
    "                         modelo: Doc2Vec) -> Tuple[np.ndarray, List[str]]:\n",
    "\n",
    "    print(f\"Aplicando undersampling a clases: {clases_objetivo}\")\n",
    "    \n",
    "    # Filtrar documentos de las clases objetivo\n",
    "    indices_objetivo = [i for i, etiq in enumerate(etiquetas) if etiq in clases_objetivo]\n",
    "    docs_filtrados = [documentos[i] for i in indices_objetivo]\n",
    "    etiquetas_filtradas = [etiquetas[i] for i in indices_objetivo]\n",
    "    \n",
    "    # Vectorizar documentos\n",
    "    X = np.array([modelo.infer_vector(doc) for doc in docs_filtrados])\n",
    "    \n",
    "    # Configurar estrategia de sampling\n",
    "    sampling_strategy = {clase: n_muestras for clase in clases_objetivo}\n",
    "    \n",
    "    # Aplicar Near Miss\n",
    "    nm = NearMiss(version=1, sampling_strategy=sampling_strategy)\n",
    "    X_resampled, y_resampled = nm.fit_resample(X, etiquetas_filtradas)\n",
    "    \n",
    "    print(f\"Documentos antes del undersampling: {len(docs_filtrados)}\")\n",
    "    print(f\"Documentos después del undersampling: {len(X_resampled)}\")\n",
    "    \n",
    "    # Convertir a lista si es necesario\n",
    "    if hasattr(y_resampled, 'tolist'):\n",
    "        y_resampled = y_resampled.tolist()\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3960a2d",
   "metadata": {},
   "source": [
    "### 3.2 Oversampling Híbrido (Word2Vec + SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "877c3218",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generar_muestras_word2vec(documentos: List[List[str]], n_muestras: int) -> List[List[str]]:\n",
    "    if n_muestras <= 0:\n",
    "        return []\n",
    "    \n",
    "    print(f\"Generando {n_muestras} muestras con Word2Vec...\")\n",
    "    \n",
    "    # Entrenar modelo Word2Vec\n",
    "    modelo_w2v = Word2Vec(documentos, window=10, min_count=1, sg=0, workers=4)\n",
    "    \n",
    "    nuevas_muestras = []\n",
    "    for _ in range(n_muestras):\n",
    "        # Seleccionar documento base aleatorio\n",
    "        doc_base = documentos[np.random.randint(0, len(documentos))]\n",
    "        \n",
    "        # Generar variación reemplazando palabras (30% probabilidad)\n",
    "        nueva_muestra = []\n",
    "        for palabra in doc_base:\n",
    "            if palabra in modelo_w2v.wv and np.random.random() < 0.3:\n",
    "                try:\n",
    "                    similares = modelo_w2v.wv.most_similar(palabra, topn=3)\n",
    "                    if similares:\n",
    "                        nueva_palabra = similares[np.random.randint(0, len(similares))][0]\n",
    "                        nueva_muestra.append(nueva_palabra)\n",
    "                    else:\n",
    "                        nueva_muestra.append(palabra)\n",
    "                except:\n",
    "                    nueva_muestra.append(palabra)\n",
    "            else:\n",
    "                nueva_muestra.append(palabra)\n",
    "        \n",
    "        nuevas_muestras.append(nueva_muestra)\n",
    "    \n",
    "    return nuevas_muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93cad23c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def aplicar_oversampling_hibrido(documentos: List[List[str]], etiqueta: str, \n",
    "                               n_muestras_objetivo: int, modelo_doc2vec: Doc2Vec) -> np.ndarray:\n",
    "\n",
    "    print(f\"\\nAplicando oversampling híbrido a clase '{etiqueta}'\")\n",
    "    print(f\"Muestras actuales: {len(documentos)}\")\n",
    "    print(f\"Muestras objetivo: {n_muestras_objetivo}\")\n",
    "    \n",
    "    if len(documentos) >= n_muestras_objetivo:\n",
    "        print(\"Ya tiene suficientes muestras, aplicando solo vectorización\")\n",
    "        return np.array([modelo_doc2vec.infer_vector(doc) for doc in documentos[:n_muestras_objetivo]])\n",
    "    \n",
    "    # Calcular muestras necesarias\n",
    "    muestras_faltantes = n_muestras_objetivo - len(documentos)\n",
    "    muestras_word2vec = muestras_faltantes // 2\n",
    "    \n",
    "    # Generar muestras con Word2Vec\n",
    "    muestras_nuevas = generar_muestras_word2vec(documentos, muestras_word2vec)\n",
    "    \n",
    "    # Combinar documentos originales y nuevos\n",
    "    documentos_combinados = documentos + muestras_nuevas\n",
    "    \n",
    "    # Vectorizar todos los documentos\n",
    "    X_vectorizado = np.array([modelo_doc2vec.infer_vector(doc) for doc in documentos_combinados])\n",
    "    \n",
    "    # Preparar para SMOTE\n",
    "    y_dummy = np.array([0] * len(documentos) + [1] * len(muestras_nuevas))\n",
    "    \n",
    "    # Calcular muestras adicionales necesarias con SMOTE\n",
    "    muestras_smote = n_muestras_objetivo - len(X_vectorizado)\n",
    "    \n",
    "    if muestras_smote > 0:\n",
    "        # Aplicar SMOTE\n",
    "        k_neighbors = min(5, len(X_vectorizado) - 1)\n",
    "        smote = SMOTE(sampling_strategy={1: len(muestras_nuevas) + muestras_smote}, \n",
    "                     k_neighbors=k_neighbors, random_state=42)\n",
    "        X_resampled, _ = smote.fit_resample(X_vectorizado, y_dummy)\n",
    "        \n",
    "        # Tomar exactamente las muestras necesarias\n",
    "        X_final = X_resampled[:n_muestras_objetivo]\n",
    "    else:\n",
    "        X_final = X_vectorizado\n",
    "    \n",
    "    print(f\"Muestras generadas con Word2Vec: {len(muestras_nuevas)}\")\n",
    "    print(f\"Muestras adicionales con SMOTE: {max(0, muestras_smote)}\")\n",
    "    print(f\"Total final: {len(X_final)}\")\n",
    "    \n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a273a66",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Aplicación del Balanceo por Clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be26ad1",
   "metadata": {},
   "source": [
    "### 4.1 Undersampling para clases con muchas muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66ac3453",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando undersampling a clases: ['Macroeconomia', 'Alianzas']\n",
      "Documentos antes del undersampling: 587\n",
      "Documentos después del undersampling: 400\n",
      "\n",
      "Resultados undersampling:\n",
      "Macroeconomia: 200 muestras\n",
      "Alianzas: 200 muestras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Aplicar undersampling a Macroeconomía y Alianzas\n",
    "clases_undersampling = ['Macroeconomia', 'Alianzas']\n",
    "X_undersampled, y_undersampled = aplicar_undersampling(\n",
    "    documentos_originales, \n",
    "    etiquetas_originales, \n",
    "    clases_undersampling, \n",
    "    200, \n",
    "    modelo_doc2vec\n",
    ")\n",
    "\n",
    "print(f\"\\nResultados undersampling:\")\n",
    "for clase in clases_undersampling:\n",
    "    count = y_undersampled.count(clase)\n",
    "    print(f\"{clase}: {count} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaea272",
   "metadata": {},
   "source": [
    "### 4.2 Oversampling para clases con pocas muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bb1a9fc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def separar_documentos_por_clase(documentos: List[List[str]], etiquetas: List[str]) -> Dict[str, List[List[str]]]:\n",
    "    docs_por_clase = {}\n",
    "    for doc, etiqueta in zip(documentos, etiquetas):\n",
    "        if etiqueta not in docs_por_clase:\n",
    "            docs_por_clase[etiqueta] = []\n",
    "        docs_por_clase[etiqueta].append(doc)\n",
    "    \n",
    "    return docs_por_clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d247a9b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Procesando clase: Regulaciones ---\n",
      "\n",
      "Aplicando oversampling híbrido a clase 'Regulaciones'\n",
      "Muestras actuales: 142\n",
      "Muestras objetivo: 200\n",
      "Generando 29 muestras con Word2Vec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras generadas con Word2Vec: 29\n",
      "Muestras adicionales con SMOTE: 29\n",
      "Total final: 200\n",
      "\n",
      "--- Procesando clase: Sostenibilidad ---\n",
      "\n",
      "Aplicando oversampling híbrido a clase 'Sostenibilidad'\n",
      "Muestras actuales: 137\n",
      "Muestras objetivo: 200\n",
      "Generando 31 muestras con Word2Vec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras generadas con Word2Vec: 31\n",
      "Muestras adicionales con SMOTE: 32\n",
      "Total final: 200\n",
      "\n",
      "--- Procesando clase: Otra ---\n",
      "\n",
      "Aplicando oversampling híbrido a clase 'Otra'\n",
      "Muestras actuales: 130\n",
      "Muestras objetivo: 200\n",
      "Generando 35 muestras con Word2Vec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras generadas con Word2Vec: 35\n",
      "Muestras adicionales con SMOTE: 35\n",
      "Total final: 200\n",
      "\n",
      "--- Procesando clase: Reputacion ---\n",
      "\n",
      "Aplicando oversampling híbrido a clase 'Reputacion'\n",
      "Muestras actuales: 26\n",
      "Muestras objetivo: 200\n",
      "Generando 87 muestras con Word2Vec...\n",
      "Muestras generadas con Word2Vec: 87\n",
      "Muestras adicionales con SMOTE: 87\n",
      "Total final: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naomi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Separar documentos por clase\n",
    "docs_por_clase = separar_documentos_por_clase(documentos_originales, etiquetas_originales)\n",
    "\n",
    "# Clases que necesitan oversampling\n",
    "clases_oversampling = ['Regulaciones', 'Sostenibilidad', 'Otra', 'Reputacion']\n",
    "\n",
    "# Aplicar oversampling a cada clase\n",
    "resultados_oversampling = {}\n",
    "for clase in clases_oversampling:\n",
    "    if clase in docs_por_clase:\n",
    "        print(f\"\\n--- Procesando clase: {clase} ---\")\n",
    "        vectores_balanceados = aplicar_oversampling_hibrido(\n",
    "            docs_por_clase[clase], \n",
    "            clase, \n",
    "            200, \n",
    "            modelo_doc2vec\n",
    "        )\n",
    "        resultados_oversampling[clase] = vectores_balanceados\n",
    "    else:\n",
    "        print(f\"Advertencia: Clase '{clase}' no encontrada en los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8559310",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Combinación de Resultados y Dataset Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30339cd9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def crear_dataset_balanceado(X_undersampled: np.ndarray, y_undersampled: List[str],\n",
    "                           resultados_oversampling: Dict[str, np.ndarray]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combina todos los resultados en un dataset balanceado final.\n",
    "    \n",
    "    Args:\n",
    "        X_undersampled: Vectores de clases con undersampling\n",
    "        y_undersampled: Etiquetas de clases con undersampling\n",
    "        resultados_oversampling: Diccionario con vectores de clases con oversampling\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset balanceado final\n",
    "    \"\"\"\n",
    "    print(\"Creando dataset balanceado final...\")\n",
    "    \n",
    "    # Combinar todos los vectores y etiquetas\n",
    "    vectores_finales = []\n",
    "    etiquetas_finales = []\n",
    "    \n",
    "    # Agregar resultados de undersampling\n",
    "    vectores_finales.append(X_undersampled)\n",
    "    etiquetas_finales.extend(y_undersampled)\n",
    "    \n",
    "    # Agregar resultados de oversampling\n",
    "    for clase, vectores in resultados_oversampling.items():\n",
    "        vectores_finales.append(vectores)\n",
    "        etiquetas_finales.extend([clase] * len(vectores))\n",
    "    \n",
    "    # Combinar todos los vectores\n",
    "    X_final = np.vstack(vectores_finales)\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    columnas = [f\"dim_{i}\" for i in range(X_final.shape[1])]\n",
    "    df_final = pd.DataFrame(X_final, columns=columnas)\n",
    "    df_final['Type'] = etiquetas_finales\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e73ffe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando dataset balanceado final...\n",
      "Dataset balanceado creado:\n",
      "Forma del dataset: (1200, 101)\n",
      "Columnas: 101 (100 dimensiones + 1 etiqueta)\n",
      "\n",
      "Distribución final de clases:\n",
      "Type\n",
      "Alianzas          200\n",
      "Macroeconomia     200\n",
      "Regulaciones      200\n",
      "Sostenibilidad    200\n",
      "Otra              200\n",
      "Reputacion        200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total de muestras: 1200\n",
      "Muestras por clase (objetivo: 200): [200, 200, 200, 200, 200, 200]\n"
     ]
    }
   ],
   "source": [
    "# Crear dataset final\n",
    "dataset_balanceado = crear_dataset_balanceado(X_undersampled, y_undersampled, resultados_oversampling)\n",
    "\n",
    "# Mostrar resumen del dataset final\n",
    "print(\"Dataset balanceado creado:\")\n",
    "print(f\"Forma del dataset: {dataset_balanceado.shape}\")\n",
    "print(f\"Columnas: {len(dataset_balanceado.columns)} ({len(dataset_balanceado.columns)-1} dimensiones + 1 etiqueta)\")\n",
    "\n",
    "# Mostrar distribución final\n",
    "print(\"\\nDistribución final de clases:\")\n",
    "distribucion_final = dataset_balanceado['Type'].value_counts()\n",
    "print(distribucion_final)\n",
    "\n",
    "# Verificar balanceo\n",
    "print(f\"\\nTotal de muestras: {len(dataset_balanceado)}\")\n",
    "print(f\"Muestras por clase (objetivo: 200): {distribucion_final.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e454a",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Guardado de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "109aa0a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balanceado guardado como 'archivos/dataset_balanceado_final.csv'\n",
      "\n",
      "Guardando archivos individuales por clase...\n",
      "- Alianzas: archivos/datos_balanceados_alianzas.csv (200 muestras)\n",
      "- Macroeconomia: archivos/datos_balanceados_macroeconomia.csv (200 muestras)\n",
      "- Regulaciones: archivos/datos_balanceados_regulaciones.csv (200 muestras)\n",
      "- Sostenibilidad: archivos/datos_balanceados_sostenibilidad.csv (200 muestras)\n",
      "- Otra: archivos/datos_balanceados_otra.csv (200 muestras)\n",
      "- Reputacion: archivos/datos_balanceados_reputacion.csv (200 muestras)\n"
     ]
    }
   ],
   "source": [
    "# Guardar dataset balanceado\n",
    "dataset_balanceado.to_csv('archivos/dataset_balanceado_final.csv', index=False)\n",
    "print(\"Dataset balanceado guardado como 'archivos/dataset_balanceado_final.csv'\")\n",
    "\n",
    "# Guardar también por separado para compatibilidad (opcional)\n",
    "print(\"\\nGuardando archivos individuales por clase...\")\n",
    "for clase in dataset_balanceado['Type'].unique():\n",
    "    df_clase = dataset_balanceado[dataset_balanceado['Type'] == clase].drop('Type', axis=1)\n",
    "    nombre_archivo = f'archivos/datos_balanceados_{clase.lower()}.csv'\n",
    "    df_clase.to_csv(nombre_archivo, index=False)\n",
    "    print(f\"- {clase}: {nombre_archivo} ({len(df_clase)} muestras)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff3005",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Verificación y Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b44939ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def verificar_dataset_balanceado(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Realiza verificaciones finales del dataset balanceado.\n",
    "    \"\"\"\n",
    "    print(\"=== VERIFICACIÓN FINAL ===\")\n",
    "    print(f\"Forma del dataset: {df.shape}\")\n",
    "    print(f\"Clases únicas: {df['Type'].nunique()}\")\n",
    "    print(f\"Valores nulos: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    print(\"\\nDistribución por clase:\")\n",
    "    for clase, count in df['Type'].value_counts().items():\n",
    "        print(f\"  {clase}: {count} muestras\")\n",
    "    \n",
    "    print(f\"\\nRango de valores en las dimensiones:\")\n",
    "    dimensiones = [col for col in df.columns if col.startswith('dim_')]\n",
    "    print(f\"  Mínimo: {df[dimensiones].min().min():.4f}\")\n",
    "    print(f\"  Máximo: {df[dimensiones].max().max():.4f}\")\n",
    "    print(f\"  Media: {df[dimensiones].mean().mean():.4f}\")\n",
    "    \n",
    "    # Verificar que todas las clases tengan exactamente 200 muestras\n",
    "    objetivo = 200\n",
    "    todas_balanceadas = all(count == objetivo for count in df['Type'].value_counts().values)\n",
    "    print(f\"\\n¿Todas las clases tienen {objetivo} muestras? {'✓ SÍ' if todas_balanceadas else '✗ NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f22a4338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACIÓN FINAL ===\n",
      "Forma del dataset: (1200, 101)\n",
      "Clases únicas: 6\n",
      "Valores nulos: 0\n",
      "\n",
      "Distribución por clase:\n",
      "  Alianzas: 200 muestras\n",
      "  Macroeconomia: 200 muestras\n",
      "  Regulaciones: 200 muestras\n",
      "  Sostenibilidad: 200 muestras\n",
      "  Otra: 200 muestras\n",
      "  Reputacion: 200 muestras\n",
      "\n",
      "Rango de valores en las dimensiones:\n",
      "  Mínimo: -3.4970\n",
      "  Máximo: 3.9888\n",
      "  Media: 0.0419\n",
      "\n",
      "¿Todas las clases tienen 200 muestras? ✓ SÍ\n",
      "\n",
      "==================================================\n",
      "PROCESO COMPLETADO EXITOSAMENTE\n",
      "==================================================\n",
      "Dataset balanceado disponible en: 'archivos/dataset_balanceado_final.csv'\n",
      "Cada clase tiene exactamente 200 muestras.\n",
      "El dataset contiene vectores Doc2Vec de 100 dimensiones + columna 'Type' con la etiqueta.\n"
     ]
    }
   ],
   "source": [
    "verificar_dataset_balanceado(dataset_balanceado)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset balanceado disponible en: 'archivos/dataset_balanceado_final.csv'\")\n",
    "print(\"Cada clase tiene exactamente 200 muestras.\")\n",
    "print(\"El dataset contiene vectores Doc2Vec de 100 dimensiones + columna 'Type' con la etiqueta.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
